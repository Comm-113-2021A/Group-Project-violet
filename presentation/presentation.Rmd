---
title: "Factors of Alcoholism In Teens"
subtitle: ""
author: "Team Violet"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r load-packages, include = FALSE}
# Add any additional packages you need to this chunk
library(tidyverse)
library(tidymodels)
library(knitr)
library(palmerpenguins)
library(showtext)
library(xaringanthemer)
```

```{r setup, include=FALSE}
# For better figure resolution
knitr::opts_chunk$set(fig.retina = 3, dpi = 300, fig.width = 6, fig.asp = 0.618, out.width = "80%")
```

```{r load-data, include=FALSE}
student_por <- read.csv("../data/student-por.csv")

student_por <- student_por %>% mutate(Talc=(2/7*(Walc)+5/7*(Dalc)),
       Alcoholism = if_else(Talc < 3, 0, 1),
       Alcoholism = factor(Alcoholism))
```

```{r xaringan-stuff, echo = FALSE}
style_xaringan(
  title_slide_background_image = "title.png",
  title_slide_text_color = "#FFF",
  header_color = "#23395D",
  inverse_background_color = "#23395D",
  inverse_text_color = "#23395D",
  inverse_header_color = "#FFF"
)
```


class: left, middle

## Overall Goal and Basic Research Question

The goal of our research will be to identify the academic and social factors that lead to alcoholism in teenagers. We will then construct a model to identify the likelihood of teenagers to suffer from alcoholism.

---
class: inverse, middle, center

# Notatable Visualizations
---

# Alcoholism in Students

```{r alcoholism-counts, eval = TRUE, echo = FALSE}
count <- student_por %>%
  group_by(Alcoholism) %>%
  count()

count

# student_mat %>%
#   group_by(Alcoholism) %>%
#   count()
```

Roughly `r round(count[2, 2] / (count[1, 2] + count[2, 2]) * 100, 2)`% of students have a total alcohol consumption higher than 3 (out of a max of 5).
---
```{r total-dalc-walc-alcoholism, echo = FALSE} 
student_por %>% 
  ggplot() +
  geom_jitter(mapping = aes(x = Alcoholism, y = Walc), color = "blue") +
  geom_jitter(mapping = aes(x = Alcoholism, y = Dalc), color = "green") + 
  labs(y = "Scale", 
       x = "Alcoholism", 
       title = "Alcoholism by consumption", 
       subtitle = "Blue - weekday consumption, Green - weekend consumption")
```

Those who have high weekend alcohol consumption (greater than 3), tend to be alcoholics. Alcoholism seems to depend more on weekend alcohol consumption than daily alcohol consumption.

---

```{r sex, echo= FALSE}
student_por_sex <- student_por %>% 
  select(sex, Talc) %>% 
  group_by(sex) %>%
  summarise(average_talc = mean(Talc))


student_por_sex %>%
  ggplot(mapping = aes(x = sex, y = average_talc)) +
  geom_col() +
  labs(
    title = "Average Total Alcohol Consumption By Sex", 
    x = "Sex", 
    y = "Average Total Alcohol Consumption"
  )
```

Men have a higher average total alcohol consumption. 

---
```{r age, out.width="70%", fig.width=4, echo=FALSE, warning=FALSE}

student_por %>%
  ggplot(aes(x=age, y=Talc)) +
  geom_jitter() +
  geom_smooth() +
  labs(
    title = "Total Alcohol Consumption By Age", 
    x = "Age", 
    y = "Total Alcohol Consumption"
  )

```

As age increases, total alcohol consumption seems to increase. However, this is likely due to a few outlying points with high age and high total alcohol consumption. 

---
```{r reason, echo=FALSE}
student_por_reason <- student_por %>% 
  select(reason, Talc) %>% 
  group_by(reason) %>%
  summarise(average_talc = mean(Talc))

student_por_reason %>%
  ggplot(mapping = aes(x = reason, y = average_talc)) +
  geom_col() +
  labs(
    title = "Average Total Alcohol Consumption By Reason for Joining School", 
    x = "Reason", 
    y = "Average Total Alcohol Consumption"
  )

```

High schoolers who choose their school based on reputation have the lowest total alohol consumption while those who choose for reasons besides courses, closeness to home, and reputation, have the highest.
---
```{r Pstatus, echo=FALSE, warning=FALSE}
student_por_Pstatus <- student_por %>% 
  select(Pstatus, Talc) %>% 
  group_by(Pstatus) %>%
  summarise(average_talc = mean(Talc))


student_por_Pstatus %>%
  ggplot(mapping = aes(x = Pstatus, y = average_talc)) +
  geom_col() +
  labs(
    title = "Average Total Alcohol Consumption By Parental Cohabitation Status", 
    x = "Cohabitation Status", 
    y = "Average Total Alcohol Consumption"
  )
```

High schoolers with parents who live together have a higher average total alcohol consumption value than those whose parents live apart. 

---
class: inverse, middle, center

# Attempt: Linear Models

---

# Linear Model

We first attempted to create a linear regression model to predict total alcohol consumption with variables we suspected to be associated with total alcohol consumption based on visualizations. 

The following equation was established from our initial model: 

$$\hat{Total Alcohol Level} = 0.07(MS School) +0.06(Age)+0.03(Failures)-0.02(Free time)+0.54(Male)+$$
$$0.17(FatherJobHealth)+0.11(FatherJobOther)+0.30(FatherJobService)-0.05(FatherJobTeacher)-$$
$$0.24(MotherJobHealth)-0.09(MotherJobOther)-0.04(MotherJobService)+0.05(MotherJobTeacher)+$$
$$0.12(ReasonHome)+0.29(ReasonOther)+0.005(ReasonReputation)-0.081(StudyTime)+$$
$$0.03(FamilySupportYes)+0.23(GoingOut)+0.04(Health)+0.03(Absences)-0.49$$
This model indicates that holding all other variables constant, a change in one of them would be a change in predicted Total Alcohol level by the related coefficient. The intercept would not be interpretable in this context.

.pull-left[
```{r new_model, echo = FALSE}
lin_model <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Talc ~ school +
        age + 
        failures + 
        freetime + 
        sex +
        Fjob + 
        Mjob +
        reason + 
        studytime +
        famsup +
        goout +
        health +
        absences, data = student_por)
```
]

---

# Residual Plot One

The residual plot shows obvious problems, as there are distinct negatively sloped lines in the plot.
This may mean that the prediction confidence may be too low, and a artificially low standard error.

```{r resid, out.width="70%", fig.width=4, echo = FALSE}
aug <- augment(lin_model$fit)

aug %>%
  ggplot(mapping = aes(x = .fitted, y = .resid)) +
  geom_jitter() + 
  geom_hline(yintercept = 0)
```

---

# Residual Plot Two

```{r linear_reg, echo=FALSE}
lin_model_all <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Talc ~ school +
        sex +
        age + 
        address + 
        famsize + 
        Pstatus + 
        Medu +
        Fedu +
        Mjob + 
        Fjob + 
        reason +
        guardian +
        traveltime +
        studytime +
        failures +
        schoolsup +
        famsup +
        paid +
        activities +
        nursery +
        higher +
        internet +
        romantic +
        famrel +
        freetime +
        goout +
        health +
        absences, data = student_por)
```

A residual plot of the second linear model with all variables as predictors shows the same trends as the previous one. This further supports the fact that a linear model would be inapporpiate in this setting.

```{r resid-all, out.width="70%", fig.width=4, echo = FALSE}
aug2 <- augment(lin_model_all$fit)

aug2 %>%
  ggplot(mapping = aes(x = .fitted, y = .resid)) +
  geom_jitter() + 
  geom_hline(yintercept = 0)
```

---

class: inverse, middle, center

# Attempt: Logistic Models

---

# Logistic Model

A linear model does not work, so we moved to a logistic model to predict alcoholism in students. 
A student is an Alcoholic if they have a total alcohol consumption greater than or equal to three.

For the first model, we choose predictors that we thought heavily influenced student alcohol consumption. These predictors are:
- The students school
- Age
- Sex
- The number of past failures 
- Freetime after school
- Father's job
- Mother's job
- The reason to choose this school
- Weekly study time
- Family educational support
- Time spent going out with friends
- Current health status
- Number of school absences

---

From the regression, the following model was generated:

$$\hat{log(alcoholism)} = 0.39(MSSchool)+0.24(Age)+0.25(Faillures)-0.03(Freetime)+1.49(Male)+$$
$$0.72(FatherJobHealth)+0.31(FatherJobOther)+0.91(FatherJobService)-0.45(FatherJobTeacher)-$$
$$0.83(MotherJobHealth)-0.10(MotherJobOther)-0.33(MotherJobService)+0.41(MotherJobTeacher)+$$
$$0.51(ReasonHome)+0.93(ReasonOther)+0.21(ReasonReputation)-0.21(StudyTime)-$$
$$0.06(FamilySupportYes)+0.54(GoingOut)+0.10(Health)+0.07(Absences)-9.8$$
This model indicates that holding all other factors constant, an increase in one of the variables would result in the log of the odds of being alcoholic by a factor of the related coefficient.

.pull-left[
```{r logit-model, echo = FALSE}
alcoholism_fit <- logistic_reg() %>%
  set_engine("glm") %>%
  fit(Alcoholism ~ school +
        age + 
        failures + 
        freetime + 
        sex +
        Fjob + 
        Mjob +
        reason + 
        studytime +
        famsup +
        goout +
        health +
        absences, data = student_por)
```
]

---

# Assessing Logistic Model #1

```{r split-train_one, echo = FALSE}
student_por_log <- student_por %>% 
  select(Alcoholism, 
         school,
         age,
         failures,
         freetime, 
         sex,
         Fjob, 
         Mjob,
         reason, 
         studytime,
         famsup,
         goout,
         health,
         absences)

set.seed(2542)

split_data <- initial_split(student_por_log, strata = Alcoholism)

training_data <- training(split_data)

testing_data <- testing(split_data)
```

```{r recipe_one, echo = FALSE}
recipe <-
  recipe(Alcoholism ~ school +
        age + 
        failures + 
        freetime + 
        sex +
        Fjob + 
        Mjob +
        reason + 
        studytime +
        famsup +
        goout +
        health +
        absences, data = training_data) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_corr(all_predictors(), threshold = 0.8) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep()

training_baked <- juice(recipe)

testing_baked <- recipe %>%
  bake(new_data = testing_data)

logistic_glm <- 
  logistic_reg(mode = "classification") %>%
  set_engine("glm") %>%
  fit(Alcoholism ~ ., data = training_baked)
```

```{r predictions_one, echo = FALSE}
predictions_class <- logistic_glm %>%
  predict(new_data = testing_baked) %>%
  bind_cols(testing_baked %>% select(Alcoholism))

predictions <- logistic_glm %>%
  predict(testing_baked, type = "prob") %>%
  bind_cols(predictions_class)
```

```{r evaluating_model_one, out.width="60%", fig.width=4, echo = FALSE}
predictions %>%
  conf_mat(Alcoholism, .pred_class) %>%
  pluck(1) %>%
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1, size = 8) +
  theme(panel.grid.major = element_blank()) +
  labs(
    y = "Actual Value",
    x = "Predicted Valu",
    fill = NULL,
    title = "Confusion Matrix", 
    subtitle = "Model 2"
  )

```

From the matrix it seems that out model does decently well. The predicted and actual values to not match up 28 times, but the accuracy seems to be pretty high. 
---

High accuracy and AUC values are preferred, while low log_loss values are preferred. This model has a high accuracy, low AUC and high log_loss values. (Log_loss quantifies how correct the predictions are, it takes how far off the model is into account, so a high value means that when the model is wrong it is very wrong). The ROC curve is also horrible, a good model goes high up into the top left corner to maximize the area underneath it.

.pull-left[
```{r accuracy_and_graph_one, echo = FALSE}
predictions %>%
  accuracy(Alcoholism, .pred_class) 

# Find the logloss

predictions %>%
  mn_log_loss(Alcoholism, .pred_1)

# Find the area under the ROC curve (AUC)

predictions %>%
  roc_auc(Alcoholism, .pred_1)

# Create a tibble that holds all the evaluation metrics

Model2_metrics <- tibble(
  "log_loss" = 
    mn_log_loss(predictions, Alcoholism, .pred_1) %>%
    select(.estimate),
  "accuracy" = 
    accuracy(predictions, Alcoholism, .pred_class) %>%
    select(.estimate),
  "auc" = 
    roc_auc(predictions, Alcoholism, .pred_1) %>%
    select(.estimate)
) %>%
  unnest(everything()) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  mutate(model = "Model 2")
```
]
.pull-right[
```{r graph_one, out.width="200%", fig.width=5, echo = FALSE}
predictions %>%
  roc_curve(Alcoholism, .pred_1) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_equal() +
  labs(
    y = "True Positive Rate (Sensitivity)",
    x = "False Positive Rate",
    fill = NULL,
    title = "ROC Curve",
    subtitle = "Model 2"
  )
```
]

---
# Logistic Model 2

We created another comparison logistic model with all the variables not previously used, the variables we suspected had little to no effect on an individual's alcohol consumption.

Predictors:
- Student's home address (urban or rural)
- Family Size
- Mother's education
- Father's education
- Student's guardian
- Home to school travel time
- Extra educational support
- Extra paid classes
- Extra-curricular activities (yes or no)
- Attended nursery school
- Want to pursue higher education
- Home internet access
- In a romantic relationship
- Quality of family relationships
---

```{r log-model-2, echo = FALSE, message=FALSE}
alcoholism_fit_two <- logistic_reg() %>%
  set_engine("glm") %>%
  fit(Alcoholism ~  
        address + 
        famsize + 
        Pstatus + 
        Medu +
        Fedu +
        guardian +
        traveltime +
        schoolsup +
        paid +
        activities +
        nursery +
        higher +
        internet +
        romantic +
        famrel, data = student_por)
```

From the regression, the following model was generated:

$$\hat{log(alcoholism)} = -.24(addressU)+.51(famssizeLE3)+.24(PstatusT)-.01(Medu)+.14(Fedu)-.09(guardianmother)+.63(guardianother)+.36(traveltime)-.36(schoolsupyes)+.37(paidyes)+.18(activitiesyes)-.39(nurseryyes)-.65(higheryes)+.26(internetyes)+.01(romanticyes)-.13(famrel)$$
$$0.72(FatherJobHealth)+0.31(FatherJobOther)+0.91(FatherJobService)-0.45(FatherJobTeacher)-$$
$$0.83(MotherJobHealth)-0.10(MotherJobOther)-0.33(MotherJobService)+0.41(MotherJobTeacher)+$$
$$0.51(ReasonHome)+0.93(ReasonOther)+0.21(ReasonReputation)-0.21(StudyTime)-$$
$$0.06(FamilySupportYes)+0.54(GoingOut)+0.10(Health)+0.07(Absences)-9.8$$
This model indicates that holding all other factors constant, an increase in one of the variables would result in the log of the odds of being alcoholic by a factor of the related coefficient.

---

# Assessing Logistic Model #2


```{r split-train, echo = FALSE}
student_por_log_two <- student_por %>% 
  select(Alcoholism,
         address,
         famsize, 
         Pstatus,
         Medu,
         Fedu,
         guardian,
         traveltime,
         schoolsup,
         paid,
         activities,
         nursery,
         higher,
         internet,
         romantic,
         famrel)

set.seed(2542)

split_data_two <- initial_split(student_por_log_two, strata = Alcoholism)

training_data_two <- training(split_data_two)

testing_data_two <- testing(split_data_two)
```

```{r recipe, echo = FALSE}
recipe_two <-
  recipe(Alcoholism ~ address + 
        famsize + 
        Pstatus + 
        Medu +
        Fedu +
        guardian +
        traveltime +
        schoolsup +
        paid +
        activities +
        nursery +
        higher +
        internet +
        romantic +
        famrel, data = training_data_two) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_corr(all_predictors(), threshold = 0.8) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>%
  prep()

training_baked_two <- juice(recipe_two)

testing_baked_two <- recipe_two %>%
  bake(new_data = testing_data_two)

logistic_glm_two <- 
  logistic_reg(mode = "classification") %>%
  set_engine("glm") %>%
  fit(Alcoholism ~ ., data = training_baked_two)
```

```{r predictions, echo = FALSE}
predictions_class_two <- logistic_glm_two %>%
  predict(new_data = testing_baked_two) %>%
  bind_cols(testing_baked_two %>% select(Alcoholism))

predictions_two <- logistic_glm_two %>%
  predict(testing_baked_two, type = "prob") %>%
  bind_cols(predictions_class_two)
```

```{r evaluating_model, out.width="60%", fig.width=4, echo = FALSE}
predictions_two %>%
  conf_mat(Alcoholism, .pred_class) %>%
  pluck(1) %>%
  as_tibble() %>%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = n), colour = "white", alpha = 1, size = 8) +
  theme(panel.grid.major = element_blank()) +
  labs(
    y = "Actual Value",
    x = "Predicted Valu",
    fill = NULL,
    title = "Confusion Matrix", 
    subtitle = "Model 2"
  )

```

From the matrix it is clear that this model is flawed. While it correctly predicts the majority of cases, it will never predict that someone has a total alcohol consumption over 3.
---

High accuracy and AUC values are preferred, while low log_loss values are preferred. This model has a high accuracy, but horrible AUC and log_loss values. The ROC curve is also not good.

.pull-left[
```{r accuracy_and_graph, echo = FALSE}
predictions_two %>%
  accuracy(Alcoholism, .pred_class) 

# Find the logloss

predictions_two %>%
  mn_log_loss(Alcoholism, .pred_1)

# Find the area under the ROC curve (AUC)

predictions_two %>%
  roc_auc(Alcoholism, .pred_1)

# Create a tibble that holds all the evaluation metrics

Model2_metrics <- tibble(
  "log_loss" = 
    mn_log_loss(predictions_two, Alcoholism, .pred_1) %>%
    select(.estimate),
  "accuracy" = 
    accuracy(predictions_two, Alcoholism, .pred_class) %>%
    select(.estimate),
  "auc" = 
    roc_auc(predictions_two, Alcoholism, .pred_1) %>%
    select(.estimate)
) %>%
  unnest(everything()) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  mutate(model = "Model 2")
```
]
.pull-right[
```{r graph, out.width="200%", fig.width=5, echo = FALSE}
predictions_two %>%
  roc_curve(Alcoholism, .pred_1) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path() +
  geom_abline(lty = 3) +
  coord_equal() +
  labs(
    y = "True Positive Rate (Sensitivity)",
    x = "False Positive Rate",
    fill = NULL,
    title = "ROC Curve",
    subtitle = "Model 2"
  )
```
]

---

class: inverse, middle, center

# Discussion

---

# Implications

The logistic modeling indicated:

1. As shown by our explanatory data analysis, sex was a major predictor in whether or not someone was alcoholic. Especially for males, the odds of being a alcoholic increases.

2. Interestingly, the father's job also tended to have a greater impact on increasing the odds of being alcoholic, barring Teaching. For fathers who were teachers, odds of becoming alcoholic decreased, while for mothers, increased. Teachers were the only level of Mother's job that was assosciated with an increase of being alcoholic.

However, there is likely some other factor(s) that is not considered in either model that contributes significantly to alcoholism, resulting in poor models. 

---

# Limitations

Some of the limitations within in our data analysis and results:

1. For the logistic model, the model would have been more accurate if there were more individuals who fell under the Alcoholism factor '1'.

2. The sample was only based on individuals in secondary school taking Portuguese language courses and the school itself is in Portugal. Thus the model should be carefully interpreted for those outside of this demographic.

3. Given the sample was taken within the same two school, it is possible that there is slightly non-independence among the observations due to factors like peer pressure.

4. The data set was also independently sourced from https://www.kaggle.com/uciml/student-alcohol-consumption/discussion/206577, and relied on self-reporting alcohol consumption factors.

---
class: inverse, middle, center

# Thank You! Questions?


